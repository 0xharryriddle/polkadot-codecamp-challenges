# --------------------------------------------
# 1. WalletConnect Configuration (REQUIRED)
# --------------------------------------------
# Get your Project ID from: https://cloud.walletconnect.com/
# This enables WalletConnect support for mobile wallets
NEXT_PUBLIC_WALLET_CONNECT_ID=your_project_id_here

# --------------------------------------------
# 2. Polkadot Private Key (OPTIONAL - For Real Transactions)
# --------------------------------------------
# ⚠️  SECURITY WARNING:
# - NEVER commit this file with real private keys
# - Use TEST accounts only for development
# - Use accounts with minimal funds
# - Consider using hardware wallets for production
#
# How to generate a test account:
# Quick Method: Run the generator script
#   pnpm generate-account
#   (This will output both seed and mnemonic options)
#
# Method 1: Polkadot.js Extension
#   1. Create account in extension
#   2. Export as JSON
#   3. Extract private key from JSON
#
# Method 2: Subkey Tool
#   cargo install --force --git https://github.com/paritytech/substrate subkey
#   subkey generate
#
# Method 3: Use the mnemonic directly (Recommended)
#   POLKADOT_MNEMONIC="word1 word2 ... word12"
#   Then in code: keyring.addFromUri(process.env.POLKADOT_MNEMONIC)
#
# Format Options:
# Option 1 - Seed (hex): 0x followed by 64 hex characters (32 bytes)
# Option 2 - Mnemonic: 12 or 24 words in quotes
#
# Current Status: NOT REQUIRED
# The app runs in SIMULATION mode without this key.
# All tool executions return mock responses.
# Set this key only when you want REAL blockchain transactions.
#
# Choose ONE of these options:
POLKADOT_PRIVATE_KEY=
# OR
POLKADOT_MNEMONIC=

# Optional: Public key and address (auto-derived from private key if not set)
POLKADOT_PUBLIC_KEY=
POLKADOT_ADDRESS=

# --------------------------------------------
# 3. LLM Provider Configuration
# --------------------------------------------
# Choose your default LLM provider: "ollama" or "openai"
NEXT_PUBLIC_DEFAULT_LLM_PROVIDER=ollama

# --------------------------------------------
# 4. Ollama Configuration (For Local AI)
# --------------------------------------------
# Local Ollama server endpoint
NEXT_PUBLIC_OLLAMA_BASE_URL=http://localhost:11434

# Model to use
# ⚠️  WARNING: deepseek-r1:1.5b is TOO SMALL and causes function calling issues
# ✅ RECOMMENDED: llama3.1:8b, qwen2.5:7b, or mistral:7b
# See MODELS.md for detailed comparison and setup
NEXT_PUBLIC_OLLAMA_MODEL=llama3.1:8b

# Setup Instructions:
# 1. Install Ollama from https://ollama.ai
# 2. Run: ollama serve
# 3. Pull a model: ollama pull llama3.1:8b
# 4. Verify: ollama list
# 
# For troubleshooting model issues, see MODELS.md

# --------------------------------------------
# 5. OpenAI Configuration (For Cloud AI)
# --------------------------------------------
# OpenAI API Key - Get from https://platform.openai.com/api-keys
# Required only if using NEXT_PUBLIC_DEFAULT_LLM_PROVIDER=openai
NEXT_PUBLIC_OPENAI_API_KEY=

# OpenAI model to use
# Common models:
#   - gpt-4o-mini (cost-effective with good performance)
#   - gpt-4o (most capable)
#   - gpt-4-turbo (fast and powerful)
#   - gpt-5-nano (newer nano model)
#   - gpt-3.5-turbo (cheapest)
# 
# Check https://platform.openai.com/docs/models for latest available models
NEXT_PUBLIC_OPENAI_MODEL=gpt-4o-mini

# Setup Instructions:
# 1. Sign up at https://platform.openai.com/
# 2. Create an API key at https://platform.openai.com/api-keys
# 3. Add billing information (required for API access)
# 4. Set NEXT_PUBLIC_DEFAULT_LLM_PROVIDER=openai
# 5. Set your API key in NEXT_PUBLIC_OPENAI_API_KEY
#
# Note: OpenAI charges per token usage. Monitor your usage at:
# https://platform.openai.com/usage